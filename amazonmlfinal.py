# -*- coding: utf-8 -*-
"""amazonmlfinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rfV5PYS9hhnsyGT_2lujPt7MRxgICmvD

### EDA
"""

pip install jupyter numpy pandas matplotlib

from google.colab import drive
drive.mount('/content/drive')

pip install scikit-learn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

st=pd.read_csv("/content/drive/MyDrive/student_resource/dataset/sample_test.csv")
sto=pd.read_csv("/content/drive/MyDrive/student_resource/dataset/sample_test_out.csv")

st.head()

sto.head()

test=pd.read_csv("/content/drive/MyDrive/student_resource/dataset/test.csv")

train=pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")

test.head()

test.shape

train.head()

train.shape

train.isnull().sum()

train.info()

train.columns

train['catalog_content'].head()

train['catalog_content'].tail()

train['catalog_content'].isna().sum()

train['catalog_content'].value_counts().sum()

"""Training on catalog content"""

train.columns

# X=train.drop(['image_link','price'],axis=1)
# y=train['price']

train['catalog_content'] = train['catalog_content'].fillna('').str.lower()

texts=pd.DataFrame(train['catalog_content'])

texts.info()



"""### TEXT ONLY PLOTTING"""

import re
import numpy as np

# ensure Series (one column)
texts = train['catalog_content'].astype(str)

# apply regex per row (each element is a string)
token_counts = texts.apply(lambda x: len(re.findall(r'\b\w+\b', x)))

print("Average tokens per product:", np.mean(token_counts))
print("95th percentile tokens per product:", np.percentile(token_counts, 95))

plt.hist(token_counts, bins=50)
plt.title("Token count per product description")
plt.xlabel("Number of tokens")
plt.ylabel("Frequency")
plt.show()
#here we decided token cutoff.

from collections import Counter
all_tokens = Counter()
for text in texts.sample(5000):      # subset for efficiency
    all_tokens.update(re.findall(r'\b\w+\b', text))

vocab_size = len(all_tokens)
rare_tokens = sum(1 for w, c in all_tokens.items() if c < 3)
print(f"Total vocab: {vocab_size:,}")
print(f"Tokens appearing <3 times: {rare_tokens:,} ({rare_tokens/vocab_size*100:.1f}%)")
# drop very rare tokens (appear in <3 docs)

sample_sizes = np.linspace(1000, len(texts), 10, dtype=int)
unique_counts = []
for n in sample_sizes:
    subset = texts.sample(n, random_state=42)
    vocab = set()
    for t in subset:
        vocab.update(re.findall(r'\b\w+\b', t))
    unique_counts.append(len(vocab))

plt.plot(sample_sizes, unique_counts)
plt.title("Vocabulary growth with more samples")
plt.xlabel("Sample size")
plt.ylabel("Unique tokens")
plt.show()

"""## **Text feature extraction**"""

import re
import pandas as pd
from bs4 import BeautifulSoup

# Load text data
train_df = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")

# Clean text function
def clean_text(text):
    text = str(text)
    text = BeautifulSoup(text, "lxml").get_text()           # remove HTML
    text = text.lower()                                     # lowercase
    text = re.sub(r"http\S+|www\S+", " ", text)             # remove URLs
    text = re.sub(r"[^a-z0-9\s]", " ", text)                # keep alphanum
    text = re.sub(r"\s+", " ", text).strip()                # normalize spaces
    return text

# Apply cleaning
train_df["catalog_content_clean"] = train_df["catalog_content"].apply(clean_text)

# Verify
print(train_df["catalog_content_clean"].head(3))
train_df.to_csv("/content/drive/MyDrive/student_resource/dataset/train_clean.csv", index=False)

"""## statistical + kmeans encoding"""

import pandas as pd
import numpy as np

text_stats = train_df["catalog_content"].fillna("").apply(str)
train_df["text_len"] = text_stats.str.len()
train_df["word_count"] = text_stats.str.split().apply(len)
train_df["digit_ratio"] = text_stats.apply(lambda x: sum(c.isdigit() for c in x) / len(x) if len(x) > 0 else 0)
train_df["avg_word_len"] = train_df["text_len"] / (train_df["word_count"] + 1)

from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(max_features=20000, stop_words="english", ngram_range=(1,2))
X_text_tfidf = tfidf.fit_transform(train_df["catalog_content"].fillna(""))

kmeans = KMeans(n_clusters=50, random_state=42, n_init="auto")
cluster_ids = kmeans.fit_predict(X_text_tfidf)
train_df["text_cluster"] = cluster_ids

"""## test"""

import re
import pandas as pd
import numpy as np
from bs4 import BeautifulSoup
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer

# Load text data
test_df = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/test.csv")

# Clean text function
def clean_text(text):
    text = str(text)
    text = BeautifulSoup(text, "lxml").get_text()           # remove HTML
    text = text.lower()                                     # lowercase
    text = re.sub(r"http\S+|www\S+", " ", text)             # remove URLs
    text = re.sub(r"[^a-z0-9\s]", " ", text)                # keep alphanum
    text = re.sub(r"\s+", " ", text).strip()                # normalize spaces
    return text

# Apply cleaning
test_df["catalog_content_clean"] = test_df["catalog_content"].apply(clean_text)

# Text statistics
text_stats = test_df["catalog_content"].fillna("").apply(str)
test_df["text_len"] = text_stats.str.len()
test_df["word_count"] = text_stats.str.split().apply(len)
test_df["digit_ratio"] = text_stats.apply(lambda x: sum(c.isdigit() for c in x) / len(x) if len(x) > 0 else 0)
test_df["avg_word_len"] = test_df["text_len"] / (test_df["word_count"] + 1)

# TF-IDF and clustering
tfidf = TfidfVectorizer(max_features=20000, stop_words="english", ngram_range=(1,2))
X_text_tfidf = tfidf.fit_transform(test_df["catalog_content"].fillna(""))

kmeans = KMeans(n_clusters=50, random_state=42, n_init="auto")
cluster_ids = kmeans.fit_predict(X_text_tfidf)
test_df["text_cluster"] = cluster_ids

# Save cleaned file
test_df.to_csv("/content/drive/MyDrive/student_resource/dataset/test_clean.csv", index=False)
print("Saved cleaned and clustered test data â†’ test_clean.csv")

"""## text encodings"""

from sklearn.preprocessing import OneHotEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler

train_df = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")
test_df  = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/test.csv")
train_df["catalog_content"] = train_df["catalog_content"].apply(clean_text)
tfidf = TfidfVectorizer(
    max_features=25000,
    ngram_range=(1, 2),
    stop_words="english",
    min_df=3
)
X_train_tfidf = tfidf.fit_transform(train_df["catalog_content"])
X_test_tfidf  = tfidf.transform(test_df["catalog_content"])

import numpy as np
from sentence_transformers import SentenceTransformer
from scipy.sparse import hstack
from tqdm import tqdm

model_st = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda')
X_embed = model_st.encode(train_df['catalog_content'].fillna(''), batch_size=64, show_progress_bar=True)

X= hstack([X_train_tfidf, np.array(X_embed)])

import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from scipy.sparse import hstack
from tqdm import tqdm
train_df = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")
test_df  = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/test.csv")

model_st = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda')
X_testing_embed = model_st.encode(test_df['catalog_content'].fillna(''), batch_size=64, show_progress_bar=True)
X_testing=hstack([X_test_tfidf, np.array(X_testing_embed)])

import scipy.sparse as sp

sp.save_npz("/content/drive/MyDrive/student_resource/text_tfidf_train.npz", X)
sp.save_npz("/content/drive/MyDrive/student_resource/text_tfidf_test.npz", X_testing)

train_df[["sample_id"]].to_csv("/content/drive/MyDrive/student_resource/text_tfidf_train_ids.csv", index=False)
test_df[["sample_id"]].to_csv("/content/drive/MyDrive/student_resource/text_tfidf_test_ids.csv", index=False)

y

"""## optional text only training"""

y=np.log1p(train_df["price"])

from sklearn.model_selection import train_test_split
ids = train_df["sample_id"]

# Internal 70/30 split
X_train, X_val, y_train, y_val, id_train, id_val = train_test_split(
    X, y, ids, train_size=0.7, random_state=30
)


train_text = pd.DataFrame(X_train.toarray())
train_text["sample_id"] = id_train.values
train_text["price"] = y_train.values

val_text = pd.DataFrame(X_val.toarray())
val_text["sample_id"] = id_val.values
val_text["price"] = y_val.values

# Save for later merging
train_text.to_csv("text_embeddings_train_split.csv", index=False)
val_text.to_csv("text_embeddings_val_split.csv", index=False)

X_train.shape, Y_train.shape, X_test.shape, Y_test.shape

"""## model improvement visualisations and analysis"""

import matplotlib.pyplot as plt
import numpy as np

plt.hist(Y_train, bins=100)
plt.title("Price Distribution (Raw)")
plt.xlabel("Price")
plt.ylabel("Count")
plt.show()

print("Skewness (raw):", pd.Series(Y_train).skew())
print("Kurtosis (raw):", pd.Series(Y_train).kurt())

density = X_train.nnz / (X_train.shape[0] * X_train.shape[1])
print(f"Feature density: {density*100:.2f}%")

train['qty'] = train['catalog_content'].str.extract(r'(\d+)\s*(?:pcs|pieces|pack|x)\b', expand=False).astype(float)
train['qty'].fillna(1, inplace=True)
print(train['qty'].corr(train['price']))

train['brand'] = train['catalog_content'].str.extract(r'(^[A-Za-z0-9]+)')
brand_stats = train.groupby('brand')['price'].mean().sort_values(ascending=False)
print(brand_stats.head(10))

"""## LGBMRegressor"""

import warnings
warnings.filterwarnings("ignore")
from sklearn.metrics import mean_squared_error
from lightgbm import LGBMRegressor
import numpy as np

# initialize model
model = LGBMRegressor(
    n_estimators=1200,
    learning_rate=0.05,
    max_depth=7,
    num_leaves=64,
    subsample=0.8,
    colsample_bytree=0.8,
    reg_alpha=0.1,
    reg_lambda=0.2,
    random_state=42,
    n_jobs=-1
)

# train
model.fit(X_train, Y_train)

# predict
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# evaluate
train_rmse = np.sqrt(mean_squared_error(Y_train, y_pred_train))
test_rmse = np.sqrt(mean_squared_error(Y_test, y_pred_test))

print("Training RMSE:", train_rmse)
print("Test RMSE:", test_rmse)

y_val_pred = model.predict(X_val)
results = pd.DataFrame({
    "sample_id": id_val.values,
    "actual_price": y_val.values,
    "predicted_price": y_val_pred
})

"""
## Other Regressor Testing"""

# pip install lightgbm catboost xgboost scikit-learn numpy pandas matplotlib

# from catboost import CatBoostRegressor
# from sklearn.metrics import mean_squared_error
# import numpy as np

# cat_model = CatBoostRegressor(
#     iterations=1000,
#     learning_rate=0.05,
#     depth=8,
#     loss_function='RMSE',
#     verbose=False,
#     random_seed=42
# )

# cat_model.fit(X_train, Y_train)

# y_pred_log_cat = cat_model.predict(X_test)
# y_pred_cat = np.expm1(y_pred_log_cat)

# rmse_cat = np.sqrt(mean_squared_error(Y_test, y_pred_cat))
# print("CatBoost RMSE:", rmse_cat)

# from xgboost import XGBRegressor
# from sklearn.metrics import mean_squared_error
# import numpy as np

# xgb_model = XGBRegressor(
#     n_estimators=1000,
#     learning_rate=0.05,
#     max_depth=8,
#     subsample=0.8,
#     colsample_bytree=0.8,
#     objective='reg:squarederror',
#     random_state=42
# )

# xgb_model.fit(X_train, Y_train)

# y_pred_log_xgb = xgb_model.predict(X_test)
# y_pred_xgb = np.expm1(y_pred_log_xgb)

# rmse_xgb = np.sqrt(mean_squared_error(Y_test, y_pred_xgb))
# print("XGBoost RMSE:", rmse_xgb)

# SMAPE = smape(Y_test, y_pred_xgb)
# print(f"SMAPE: {SMAPE:.2f}%")

"""## Image Transformations

## getting train images
"""

from google.colab import drive; drive.mount('/content/drive')

import sys
sys.path.append('/content/drive/MyDrive/student_resource/src')
from utils import download_images

train = pd.read_csv('/content/drive/MyDrive/student_resource/dataset/train.csv')

output_folder = '/content/drive/MyDrive/student_resource/train_images'
os.makedirs(output_folder, exist_ok=True)

download_images(train['image_link'], output_folder)

"""## testing different image embeddings"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os
from sklearn.preprocessing import normalize
import numpy as np
import pandas as pd

# =========================
# 1. Define custom dataset
# =========================
class PriceDataset(Dataset):
    def __init__(self, df, img_folder, transform=None):
        self.df = df
        self.img_folder = img_folder
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = os.path.join(self.img_folder, os.path.basename(str(row["image_link"])).split("?")[0])
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        price = torch.tensor(row["price"], dtype=torch.float32)
        return image, price

# =========================
# 2. Transforms
# =========================
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# =========================
# 3. Load data
# =========================
import pandas as pd
from torch.utils.data import DataLoader

train_meta = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")

# drop the single missing image
train_meta = train_meta[~train_meta["image_link"].str.contains("51mjZYDYjyL.jpg", na=False)]

# rebuild dataset and loader
train_dataset = PriceDataset(
    train_meta,
    "/content/drive/MyDrive/student_resource/train_images",
    transform
)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)

# =========================
# 4. Model setup (Fine-tune)
# =========================
device = "cuda" if torch.cuda.is_available() else "cpu"
cnn = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
for param in list(cnn.parameters())[:-20]:  # freeze all but last few layers
    param.requires_grad = False

cnn.fc = nn.Linear(cnn.fc.in_features, 1)  # replace classifier with regressor
cnn = cnn.to(device)

# =========================
# 5. Train
# =========================
criterion = nn.L1Loss()
optimizer = optim.Adam(filter(lambda p: p.requires_grad, cnn.parameters()), lr=1e-4)

for epoch in range(3):  # light fine-tuning
    cnn.train()
    epoch_loss = 0.0
    for imgs, prices in train_loader:
        imgs, prices = imgs.to(device), prices.to(device).unsqueeze(1)
        optimizer.zero_grad()
        preds = cnn(imgs)
        loss = criterion(preds, prices)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item() * imgs.size(0)
    print(f"Epoch {epoch+1} Loss: {epoch_loss/len(train_loader.dataset):.4f}")

# =========================
# 6. Extract embeddings
# =========================
cnn.fc = nn.Identity()  # remove regression head
cnn.eval()
img_embeddings = {}
with torch.no_grad():
    for imgs, _ in DataLoader(train_dataset, batch_size=32):
        imgs = imgs.to(device)
        feats = cnn(imgs).cpu().numpy()
        for i, row in enumerate(train_dataset.df.iloc[:len(feats)].itertuples()):
            img_embeddings[os.path.basename(str(row.image_link)).split("?")[0]] = feats[i]

# Save
torch.save(img_embeddings, "/content/drive/MyDrive/student_resource/embeddings/fine_tuned_embeddings_reexport.pt")

# ======================================================
# OPTIMIZED OCR + EMBEDDING PIPELINE (GPU ACCELERATED)
# ======================================================
# Uses Tesseract (CPU parallel) + SentenceTransformer (GPU)
# ======================================================

import subprocess
import sys

# Install packages
try:
    import pytesseract
except:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "pytesseract"])
    import pytesseract

try:
    from PIL import Image
except:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "pillow"])
    from PIL import Image

try:
    from sentence_transformers import SentenceTransformer
except:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "sentence-transformers"])
    from sentence_transformers import SentenceTransformer

try:
    from tqdm import tqdm
except:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "tqdm"])
    from tqdm import tqdm

import pandas as pd
import numpy as np
import os
import torch
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# Set tesseract path
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ----------------------------
# CONFIGURATION
# ----------------------------
IMG_DIR = r"D:\inna_project\downloaded_train_images"
OUT_OCR_TEXT = r"D:\inna_project\ocr_text.csv"
OUT_EMBEDS = r"D:\inna_project\ocr_embeddings.csv"
MODEL_NAME = "all-MiniLM-L6-v2"
BATCH_SIZE = 256
NUM_WORKERS = 8  # Parallel OCR threads

# Check GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")
if device == "cuda":
    print(f"GPU: {torch.cuda.get_device_name(0)}")

# Test Tesseract
print("\n>>> Testing Tesseract...")
try:
    version = pytesseract.get_tesseract_version()
    print(f"âœ“ Tesseract version: {version}")
except Exception as e:
    print(f"âœ— ERROR: {e}")
    raise

# ----------------------------
# OCR Processing with ThreadPoolExecutor (Windows-friendly)
# ----------------------------
def process_single_image(img_path):
    """Process one image with Tesseract"""
    fname = os.path.basename(img_path)
    sample_id = os.path.splitext(fname)[0]
    try:
        img = Image.open(img_path)
        img = img.convert("L").resize((800, 800))  # Grayscale + resize for speed
        text = pytesseract.image_to_string(img, config="--psm 6")
        return {"sample_id": sample_id, "ocr_text": text.strip()}
    except Exception as e:
        return {"sample_id": sample_id, "ocr_text": ""}

print("\n>>> Running OCR extraction with parallel processing...")
files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith((".jpg", ".jpeg", ".png"))]
image_paths = [os.path.join(IMG_DIR, f) for f in files]
print(f"Found {len(files)} images")
print(f"Using {NUM_WORKERS} parallel threads...\n")

start_time = time.time()
records = []
processed = 0

# ThreadPoolExecutor works reliably on Windows
with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:
    # Submit all tasks
    future_to_path = {executor.submit(process_single_image, path): path for path in image_paths}

    # Process results as they complete
    with tqdm(total=len(files), desc="OCR Progress", unit="img") as pbar:
        for future in as_completed(future_to_path):
            result = future.result()
            records.append(result)
            processed += 1
            pbar.update(1)

            # Print stats every 1000 images
            if processed % 1000 == 0:
                elapsed = time.time() - start_time
                rate = processed / elapsed
                remaining = (len(files) - processed) / rate if rate > 0 else 0
                print(f"   {processed}/{len(files)} | Speed: {rate:.1f} img/sec | ETA: {remaining/60:.1f} min")

ocr_df = pd.DataFrame(records)
ocr_df.to_csv(OUT_OCR_TEXT, index=False)

elapsed = time.time() - start_time
print(f"\n[âœ“] OCR complete: {len(ocr_df)} images in {elapsed/60:.1f} minutes")
print(f"    Average speed: {len(ocr_df)/elapsed:.1f} images/sec")
print(f"    Saved to: {OUT_OCR_TEXT}")

# ----------------------------
# Sentence Embeddings (GPU Accelerated)
# ----------------------------
print(f"\n>>> Encoding text with SentenceTransformer on {device.upper()}...")
ocr_model = SentenceTransformer(MODEL_NAME, device=device)
texts = ocr_df["ocr_text"].fillna("").tolist()

start_time = time.time()
embeddings = []
for i in tqdm(range(0, len(texts), BATCH_SIZE), desc="Embedding Progress"):
    batch = texts[i : i + BATCH_SIZE]
    emb = ocr_model.encode(batch, show_progress_bar=False, normalize_embeddings=True, device=device)
    embeddings.append(emb)

embeddings = np.vstack(embeddings)
elapsed = time.time() - start_time
print(f"[âœ“] Embeddings complete in {elapsed/60:.1f} minutes")
print(f"    Speed: {len(texts)/elapsed:.1f} texts/sec")

# ----------------------------
# Save Embeddings
# ----------------------------
ocr_features = pd.DataFrame(embeddings, columns=[f"ocr_{i}" for i in range(embeddings.shape[1])])
ocr_features["sample_id"] = ocr_df["sample_id"].astype(str)
ocr_features.to_csv(OUT_EMBEDS, index=False)

print(f"\n[âœ“] Embeddings saved to: {OUT_EMBEDS}")
print(f"    Shape: {ocr_features.shape}")
print("\n" + "="*60)
print("PROCESSING COMPLETE!")
print("="*60)
print(f"Total images processed: {len(ocr_df)}")
print(f"Output files:")
print(f"  - {OUT_OCR_TEXT}")
print(f"  - {OUT_EMBEDS}")
print("="*60)

# ============================================================
# CLIP EMBEDDING EXTRACTION â€” REPLACES RESNET FINE-TUNE BLOCK
# ============================================================
import torch, os, numpy as np
from PIL import Image
import open_clip
from tqdm import tqdm
import pandas as pd

# --- Setup ---
device = "cuda" if torch.cuda.is_available() else "cpu"
model, _, preprocess = model, _, preprocess = open_clip.create_model_and_transforms(
    "ViT-B-32", pretrained="laion2b_s34b_b79k"
)


model = model.to(device).eval()

# --- Image folder and metadata ---
train_meta = pd.read_csv("/content/local_copy/dataset/train.csv")
image_dir = "/content/drive/MyDrive/student_resource/train_images"

# Optional filter for missing/corrupt links
train_meta = train_meta[~train_meta["image_link"].str.contains("51mjZYDYjyL.jpg", na=False)]

# --- Extraction ---
img_embeddings = {}
with torch.no_grad():
    for row in tqdm(train_meta.itertuples(), total=len(train_meta)):
        fname = os.path.basename(str(row.image_link)).split("?")[0]
        path = os.path.join(image_dir, fname)
        try:
            image = preprocess(Image.open(path).convert("RGB")).unsqueeze(0).to(device)
            emb = model.encode_image(image).cpu().numpy()[0]
            emb = emb / (np.linalg.norm(emb) + 1e-8)
            img_embeddings[fname] = emb
        except Exception:
            continue

# --- Save ---
os.makedirs("/content/local_copy/embeddings", exist_ok=True)
torch.save(img_embeddings, "/content/local_copy/embeddings/clip_embeddings.pt")


print(f"Saved {len(img_embeddings)} CLIP embeddings successfully.")



img_embeddings

"""### PCA to improve image feature importance"""

import torch
 torch.serialization.add_safe_globals([__import__('numpy')._core.multiarray._reconstruct])

 img_embeddings = torch.load(
    "/content/drive/MyDrive/student_resource/embeddings/train_image_embeddings.pt",
     weights_only=False
 )

 print("âœ… Embeddings loaded successfully.")
 print("Total embeddings:", len(img_embeddings))

# Inspect shape and count
print("Total embeddings:", len(img_embeddings))

# Check dimension consistency
dims = [v.shape[0] for v in img_embeddings.values()]
print("Embedding dimension (unique):", np.unique(dims))

# Example: inspect one vector
first_key = list(img_embeddings.keys())[0]
print("Example key:", first_key)
print("First 5 values:", img_embeddings[first_key][:5])

# 1_pca_scale_images.py
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import joblib
import torch
import os

# Paths
IMG_EMBED_PATH = "/content/drive/MyDrive/student_resource/embeddings/train_image_embeddings.pt"
TRAIN_CSV = "/content/drive/MyDrive/student_resource/dataset/train.csv"
TEST_CSV  = "/content/drive/MyDrive/student_resource/dataset/test.csv"
OUT_PCA = "/content/drive/MyDrive/student_resource/embeddings/image_pca_256.joblib"
OUT_SCALER = "/content/drive/MyDrive/student_resource/embeddings/image_scaler.joblib"

# Load features dict (safe)
torch.serialization.add_safe_globals([__import__('numpy')._core.multiarray._reconstruct])
features = torch.load(IMG_EMBED_PATH, weights_only=False)  # filename -> np.array

# build DataFrame aligned to train+test filenames
all_items = []
for fname, vec in features.items():
    all_items.append((fname, vec.astype(np.float32)))
fnames, mats = zip(*all_items)
mat = np.vstack(mats)  # (N_images, D=2048)

# Standardize then PCA
scaler = StandardScaler()
mat_scaled = scaler.fit_transform(mat)   # important: center for PCA

# PCA to 256 dims (tune 128-512)
pca = PCA(n_components=256, random_state=42)
mat_pca = pca.fit_transform(mat_scaled).astype(np.float32)

# save mappings: filename -> pca_vector
fname_to_pca = {f: mat_pca[i] for i, f in enumerate(fnames)}

joblib.dump(pca, OUT_PCA)
joblib.dump(scaler, OUT_SCALER)
# save reduced features as torch file for quick loading later
torch.save(fname_to_pca, "/content/drive/MyDrive/student_resource/embeddings/image_fname_to_pca.pt")
print("Saved PCA and scaler and reduced embeddings. Shape:", mat_pca.shape)

# 2_build_img_matrices.py
import pandas as pd
import numpy as np
import torch
import os
from sklearn.preprocessing import StandardScaler
import joblib

# paths used above
TRAIN_CSV = "/content/drive/MyDrive/student_resource/dataset/train.csv"
TEST_CSV  = "/content/drive/MyDrive/student_resource/dataset/test.csv"
PCA_EMB = "/content/drive/MyDrive/student_resource/embeddings/image_fname_to_pca.pt"
OUT_XIMG_TRAIN = "/content/drive/MyDrive/student_resource/embeddings/X_img_train_pca.npy"
OUT_XIMG_TEST  = "/content/drive/MyDrive/student_resource/embeddings/X_img_test_pca.npy"

IMG_WEIGHT = 2.0   # try 1.5 - 3.0

train_df = pd.read_csv(TRAIN_CSV)
test_df  = pd.read_csv(TEST_CSV)

train_df['image_file'] = train_df['image_link'].astype(str).apply(lambda x: os.path.basename(x).split('?')[0])
test_df['image_file']  = test_df['image_link'].astype(str).apply(lambda x: os.path.basename(x).split('?')[0])

fname_to_pca = torch.load(PCA_EMB, weights_only=False)  # dict

embed_dim = next(iter(fname_to_pca.values())).shape[0]

def build_matrix(df):
    n = len(df)
    M = np.zeros((n, embed_dim), dtype=np.float32)
    for i, f in enumerate(df['image_file'].values):
        v = fname_to_pca.get(f)
        if v is not None:
            M[i] = v
    return M

X_img_train_pca = build_matrix(train_df)
X_img_test_pca  = build_matrix(test_df)

# optional: normalize each row to unit norm (helps mixing)
row_norms = np.linalg.norm(X_img_train_pca, axis=1, keepdims=True)
row_norms[row_norms==0] = 1.0
X_img_train_pca = X_img_train_pca / row_norms

row_norms = np.linalg.norm(X_img_test_pca, axis=1, keepdims=True)
row_norms[row_norms==0] = 1.0
X_img_test_pca = X_img_test_pca / row_norms

# scale/boost
X_img_train_pca *= IMG_WEIGHT
X_img_test_pca  *= IMG_WEIGHT

np.save(OUT_XIMG_TRAIN, X_img_train_pca)
np.save(OUT_XIMG_TEST, X_img_test_pca)
print("Saved X_img_train_pca, X_img_test_pca shapes:", X_img_train_pca.shape, X_img_test_pca.shape)

img_df.head()

"""## Merging and preprocessing with fine tuned embeddings"""

import torch, numpy
torch.serialization.add_safe_globals([numpy.core.multiarray._reconstruct])
fine_tuned = torch.load(
    "/content/drive/MyDrive/student_resource/embeddings/fine_tuned_embeddings.pt",
    map_location="cpu",
    weights_only=False
)
print(len(fine_tuned))

import numpy as np
import pandas as pd
import os

# fine_tuned is dict: { 'filename.jpg': np.array([...]) }
rows = []
for fname, vec in fine_tuned.items():
    sample_id = os.path.splitext(fname)[0]     # remove .jpg
    rows.append([sample_id] + list(vec))

img_features = pd.DataFrame(rows, columns=["sample_id"] + [f"img_{i}" for i in range(len(vec))])
print(img_features.shape)

"""### OCR merging and loading [redacted later]"""

# import torch
# import pandas as pd

# ocr_embeddings = torch.load("/content/drive/MyDrive/student_resource/ocr_embeddings.pt", map_location="cpu")

# !find /content/drive/MyDrive -type f -iname "*fine_tuned_embeddings_reexport*.pt"

# !ls -lh "/content/drive/MyDrive/student_resource/embeddings"

# import pandas as pd
# ocr_df = pd.read_csv("/content/drive/MyDrive/ocr_embeddings.csv")

# print(ocr_df.shape)
# ocr_df.head(2)

# !find /content/drive/MyDrive/student_resource -type f -iname "*ocr_embeddings*"

# import pandas as pd

# ocr_df = pd.read_csv("/content/drive/MyDrive/student_resource/embeddings/ocr_embeddings.csv")
# print("Shape:", ocr_df.shape)
# ocr_df.head(2)

# assert any("image" in c.lower() for c in ocr_df.columns), "No image name column detected."

# ocr_df.columns.tolist()



"""### FINAL MERGE"""

import scipy.sparse as sp

X_text = sp.load_npz("/content/drive/MyDrive/student_resource/text_tfidf_train.npz")
text_ids = pd.read_csv("/content/drive/MyDrive/student_resource/text_tfidf_train_ids.csv")
train_meta = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")

# Ensure both sample_id columns are strings
text_ids["sample_id"] = text_ids["sample_id"].astype(str)
img_features["sample_id"] = img_features["sample_id"].astype(str)
train_meta["sample_id"] = train_meta["sample_id"].astype(str)

# Align image embeddings to text order
merged = pd.merge(text_ids, img_features, on="sample_id", how="inner")
print("Aligned rows:", merged.shape[0])

print(text_ids["sample_id"].head().tolist())
print(list(fine_tuned.keys())[:5])

"""### correcting for merge"""

import os
import pandas as pd
import numpy as np

# Load train metadata
train_meta = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")

# Extract clean filenames from URLs
train_meta["image_basename"] = train_meta["image_link"].apply(
    lambda x: os.path.basename(str(x)).split("?")[0]
)

# Create mapping from image filename â†’ sample_id
fname_to_id = dict(zip(train_meta["image_basename"], train_meta["sample_id"].astype(str)))

# Map fine-tuned embeddings
rows = []
for fname, vec in fine_tuned.items():
    sid = fname_to_id.get(fname)
    if sid:
        rows.append([sid] + list(vec))

img_features = pd.DataFrame(rows, columns=["sample_id"] + [f"img_{i}" for i in range(len(vec))])
print("Image features shape:", img_features.shape)

text_ids.shape

img_features["sample_id"].head()
print(text_ids["sample_id"].head().tolist())
print(img_features["sample_id"].head().tolist())

"""MERGING text features (IDs) with image embeddings"""

merged = pd.merge(text_ids, img_features, on="sample_id", how="inner")
print("Aligned rows:", merged.shape[0])

"""MERGING target variable (price)"""

# Load price data
train_meta = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")[["sample_id", "price"]]
train_meta["sample_id"] = train_meta["sample_id"].astype(str)

# Merge price with aligned embeddings
merged = pd.merge(merged, train_meta, on="sample_id", how="left")

# Verify
print("Merged with price:", merged.shape)
print("Missing prices:", merged["price"].isna().sum())

# Final feature + target extraction
X_combined = merged.drop(columns=["sample_id", "price"], errors="ignore").astype(np.float32)
y = merged["price"].astype(float).values

#OCR DROPPED FOR CREATING NOISE
# ocr_df['sample_id'] = ocr_df['sample_id'].astype(str)
# merged['sample_id'] = merged['sample_id'].astype(str)

# merged_full = merged.merge(ocr_df, on='sample_id', how='left')
# print("Merged with OCR:", merged_full.shape)
# print("Missing OCR values:", merged_full.filter(like="ocr_").isna().sum().sum())

# ocr_cols = [c for c in merged_full.columns if c.startswith("ocr_")]
# merged_full[ocr_cols] = merged_full[ocr_cols].fillna(0)

"""## combining stat features with fine tuned embeddings"""

aux_features = train_df[["sample_id", "text_len", "word_count", "digit_ratio", "avg_word_len", "text_cluster"]]

train_df["sample_id"] = train_df["sample_id"].astype(str)
merged["sample_id"] = merged["sample_id"].astype(str)
aux_features["sample_id"] = aux_features["sample_id"].astype(str)

print(train_df["sample_id"].head())
print(merged["sample_id"].head())
print(aux_features["sample_id"].head())

mergedfeat = merged.merge(aux_features, on="sample_id", how="left")
print("Merged shape:", mergedfeat.shape)
print("Missing aux features:", mergedfeat[["text_len", "text_cluster"]].isna().sum().sum())

import scipy.sparse as sp
print(type(X_text))
print(X_text.shape)
print(X_text.nnz, "non-zero entries")
print("Density:", X_text.nnz / (X_text.shape[0] * X_text.shape[1]))

print(type(X_text))  # <class 'scipy.sparse._csr.csr_matrix'>
print(X_text.shape)

import numpy as np, pandas as pd, scipy.sparse as sp

# Convert COO to CSR once
X_text = X_text.tocsr()

# Align IDs
common = pd.merge(
    mergedfeat[["sample_id"]],
    text_ids[["sample_id"]],
    on="sample_id",
    how="inner"
)

# Get index positions in each source
idx_text = text_ids[text_ids["sample_id"].isin(common["sample_id"])].index
idx_img  = mergedfeat[mergedfeat["sample_id"].isin(common["sample_id"])].index

# Slice and reorder
X_text_aligned = X_text[idx_text]
X_img_hc_aligned = mergedfeat.iloc[idx_img].drop(columns=["sample_id", "price"]).to_numpy(dtype=np.float32)

# Concatenate numerically
X_full = sp.hstack([X_text_aligned, sp.csr_matrix(X_img_hc_aligned)], format="csr")

# Target
y = mergedfeat.iloc[idx_img]["price"].astype(float).values

print(X_full.shape, len(y))

X_combined = X_full   # (68459, 27437) sparse matrix
y = mergedfeat.loc[mergedfeat["sample_id"].isin(common["sample_id"]), "price"].astype(float).values

lower, upper = mergedfeat["price"].quantile([0.01, 0.99])
y = np.clip(mergedfeat["price"].astype(float).values, lower, upper)

print("y shape:", y.shape)
print("clipped price range:", y.min(), "to", y.max())

print(y[:10])
print(y.ndim)  # should output 1

import joblib, os
from google.colab import drive

# Mount Drive (if not already)
drive.mount('/content/drive')

# Define persistent path
save_path = "/content/drive/MyDrive/model_saves/"
os.makedirs(save_path, exist_ok=True)

# Save combined feature matrix and target vector
joblib.dump(X_full, f"{save_path}X_combined.joblib")
joblib.dump(y, f"{save_path}y.joblib")

print("Saved:")
print(f"  X_combined â†’ {save_path}X_combined.joblib")
print(f"  y          â†’ {save_path}y.joblib")

merged.fillna(0, inplace=True)

assert merged["sample_id"].nunique() == merged.shape[0], "Duplicate sample_ids"
assert not merged.isna().any().any(), "NaNs remain after merge"

"""## **TEST MERGE EMBEDDINGS**"""

import torch, numpy
torch.serialization.add_safe_globals([numpy.core.multiarray._reconstruct])

# --- Load fine-tuned embeddings for test ---
finetunedembeddingstest = torch.load(
    "/content/drive/MyDrive/student_resource/embeddings/fine_tuned_embeddings_test.pt",
    map_location="cpu",
    weights_only=False
)
print(len(finetunedembeddingstest))

import numpy as np
import pandas as pd
import os
import scipy.sparse as sp

# fine_tuned is dict: { 'filename.jpg': np.array([...]) }
rows = []
for fname, vec in finetunedembeddingstest.items():
    sample_id = os.path.splitext(fname)[0]
    rows.append([sample_id] + list(vec))

img_features_test = pd.DataFrame(rows, columns=["sample_id"] + [f"img_{i}" for i in range(len(vec))])
print(img_features_test.shape)

# --- Load text features and IDs ---
X_text_test = sp.load_npz("/content/drive/MyDrive/student_resource/text_tfidf_test.npz")
text_ids_test = pd.read_csv("/content/drive/MyDrive/student_resource/text_tfidf_test_ids.csv")
test_meta = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/test.csv")

# Ensure string IDs
text_ids_test["sample_id"] = text_ids_test["sample_id"].astype(str)
img_features_test["sample_id"] = img_features_test["sample_id"].astype(str)
test_meta["sample_id"] = test_meta["sample_id"].astype(str)

# Align image embeddings to text order
merged_test = pd.merge(text_ids_test, img_features_test, on="sample_id", how="inner")
print("Aligned rows:", merged_test.shape[0])

# --- Map image filenames to sample_ids ---
test_meta["image_basename"] = test_meta["image_link"].apply(
    lambda x: os.path.basename(str(x)).split("?")[0]
)
fname_to_id_test = dict(zip(test_meta["image_basename"], test_meta["sample_id"].astype(str)))

# --- Rebuild mapping from embeddings dict ---
rows = []
for fname, vec in finetunedembeddingstest.items():
    sid = fname_to_id_test.get(fname)
    if sid:
        rows.append([sid] + list(vec))

img_features_test = pd.DataFrame(rows, columns=["sample_id"] + [f"img_{i}" for i in range(len(vec))])
print("Image features shape:", img_features_test.shape)

merged_test = pd.merge(text_ids_test, img_features_test, on="sample_id", how="inner")
print("Aligned rows:", merged_test.shape[0])

# --- Auxiliary text-based features ---
aux_features_test = test_df[["sample_id", "text_len", "word_count", "digit_ratio", "avg_word_len", "text_cluster"]]

test_df["sample_id"] = test_df["sample_id"].astype(str)
merged_test["sample_id"] = merged_test["sample_id"].astype(str)
aux_features_test["sample_id"] = aux_features_test["sample_id"].astype(str)

mergedfeat_test = merged_test.merge(aux_features_test, on="sample_id", how="left")
print("Merged shape:", mergedfeat_test.shape)
print("Missing aux features:", mergedfeat_test[["text_len", "text_cluster"]].isna().sum().sum())

# --- Sparse alignment ---
X_text_test = X_text_test.tocsr()
common = pd.merge(
    mergedfeat_test[["sample_id"]],
    text_ids_test[["sample_id"]],
    on="sample_id",
    how="inner"
)

idx_text = text_ids_test[text_ids_test["sample_id"].isin(common["sample_id"])].index
idx_img = mergedfeat_test[mergedfeat_test["sample_id"].isin(common["sample_id"])].index

X_text_aligned_test = X_text_test[idx_text]
X_img_hc_aligned_test = mergedfeat_test.iloc[idx_img].drop(columns=["sample_id"], errors="ignore").to_numpy(dtype=np.float32)

X_full_test = sp.hstack([X_text_aligned_test, sp.csr_matrix(X_img_hc_aligned_test)], format="csr")

print("Final test feature shape:", X_full_test.shape)

# --- Save ---
import joblib, os
from google.colab import drive

drive.mount('/content/drive', force_remount=True)
save_path = "/content/drive/MyDrive/model_saves/"
os.makedirs(save_path, exist_ok=True)

joblib.dump(X_full_test, f"{save_path}X_combined_test.joblib")
print(f"Saved test features â†’ {save_path}X_combined_test.joblib")

"""## TEST EMBEDDINGS IMAGE (RAN ON LOCAL)"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os
import pandas as pd
import numpy as np
import time

print("="*60)
print("TRAINING + TEST EMBEDDING EXTRACTION WITH GPU")
print("="*60)

# ============================================================
# 1. DATASET FOR TRAINING (WITH PRICE)
# ============================================================
class PriceDataset(Dataset):
    def __init__(self, df, img_folder, transform=None):
        self.df = df.copy().reset_index(drop=True)
        self.img_folder = img_folder
        self.transform = transform

        # Filter out images that don't exist (using sample_id naming)
        valid_indices = []
        print("Validating training images...")
        for idx, row in self.df.iterrows():
            img_name = f"{row['sample_id']}.jpg"
            img_path = os.path.join(self.img_folder, img_name)
            if os.path.exists(img_path):
                valid_indices.append(idx)

            if (idx + 1) % 10000 == 0:
                print(f"  Checked {idx + 1}/{len(self.df)} rows, found {len(valid_indices)} valid images")

        self.df = self.df.loc[valid_indices].reset_index(drop=True)
        print(f"Found {len(self.df)} valid training images out of {len(df)}")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_name = f"{row['sample_id']}.jpg"
        img_path = os.path.join(self.img_folder, img_name)

        try:
            image = Image.open(img_path).convert("RGB")
            if self.transform:
                image = self.transform(image)
            price = torch.tensor(row["price"], dtype=torch.float32)
            return image, price
        except Exception as e:
            print(f"Error loading {img_path}: {e}")
            # Return a black image as fallback
            image = torch.zeros(3, 224, 224) if self.transform else Image.new("RGB", (224, 224))
            price = torch.tensor(0.0, dtype=torch.float32)
            return image, price

# ============================================================
# 2. TRANSFORMS
# ============================================================
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# ============================================================
# 3. LOAD TRAIN DATA
# ============================================================
train_csv = r"D:\inna_project\68e8d1d70b66d_student_resource\student_resource\dataset\train.csv"
train_img_folder = r"D:\inna_project\downloaded_train_images"
train_meta = pd.read_csv(train_csv)

train_dataset = PriceDataset(train_meta, train_img_folder, transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)

# ============================================================
# 4. MODEL SETUP (FINE-TUNE) WITH GPU
# ============================================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"\nUsing device: {device}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

cnn = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
for param in list(cnn.parameters())[:-20]:
    param.requires_grad = False
cnn.fc = nn.Linear(cnn.fc.in_features, 1)
cnn = cnn.to(device)

criterion = nn.L1Loss()
optimizer = optim.Adam(filter(lambda p: p.requires_grad, cnn.parameters()), lr=1e-4)

print("\nStarting fine-tuning...")
print(f"Total batches per epoch: {len(train_loader)}")
print(f"Dataset size: {len(train_dataset)} images")

for epoch in range(3):
    cnn.train()
    total_loss = 0
    batch_count = 0
    epoch_start_time = time.time()

    for imgs, prices in train_loader:
        batch_start_time = time.time()
        imgs, prices = imgs.to(device), prices.to(device).unsqueeze(1)
        optimizer.zero_grad()
        preds = cnn(imgs)
        loss = criterion(preds, prices)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * imgs.size(0)
        batch_count += 1

        # Show progress every 20 batches
        if batch_count % 20 == 0:
            avg_loss = total_loss / (batch_count * 32)
            progress_pct = (batch_count / len(train_loader)) * 100
            elapsed = time.time() - epoch_start_time
            batches_per_sec = batch_count / elapsed if elapsed > 0 else 0
            eta_seconds = (len(train_loader) - batch_count) / batches_per_sec if batches_per_sec > 0 else 0
            eta_min = eta_seconds / 60
            print(f"  Epoch {epoch+1}/3 | Batch {batch_count}/{len(train_loader)} ({progress_pct:.1f}%) | "
                  f"Loss: {avg_loss:.4f} | ETA: {eta_min:.1f}min")

    epoch_time = time.time() - epoch_start_time
    avg_loss = total_loss / len(train_loader.dataset)
    print(f"Epoch {epoch+1}/3 Complete - Loss: {avg_loss:.4f} | Time: {epoch_time/60:.1f}min")
    print("-" * 60)

print("\nFine-tuning complete.")

# Save the fine-tuned model
os.makedirs(r"D:\inna_project\models", exist_ok=True)
torch.save(cnn.state_dict(), r"D:\inna_project\models\fine_tuned_resnet50.pth")
print("Saved fine-tuned model weights")

# ============================================================
# 5. EMBEDDING EXTRACTION (TRAINED MODEL)
# ============================================================
print("\nSwitching to embedding extraction mode...")
cnn.fc = nn.Identity()
cnn.eval()

# TEST DATASET (sample_id-based)
class TestDataset(Dataset):
    def __init__(self, df, img_folder, transform=None):
        self.df = df.copy()
        self.img_folder = img_folder
        self.transform = transform
        valid_indices = []
        print("Validating test images...")
        for idx, row in self.df.iterrows():
            sample_id = str(row["sample_id"])
            for ext in ['.jpg', '.jpeg', '.png', '.webp']:
                if os.path.exists(os.path.join(self.img_folder, f"{sample_id}{ext}")):
                    valid_indices.append(idx)
                    break
            if (idx + 1) % 5000 == 0:
                print(f"  Checked {idx + 1}/{len(self.df)} rows, found {len(valid_indices)} valid images")

        self.df = self.df.loc[valid_indices].reset_index(drop=True)
        print(f"Found {len(self.df)} valid test images")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        sample_id = str(row["sample_id"])
        img_path = None
        for ext in ['.jpg', '.jpeg', '.png', '.webp']:
            path = os.path.join(self.img_folder, f"{sample_id}{ext}")
            if os.path.exists(path):
                img_path = path
                break
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, sample_id

test_csv = r"D:\inna_project\68e8d1d70b66d_student_resource\student_resource\dataset\test.csv"
test_img_folder = r"D:\inna_project\downloaded_test_images"
test_meta = pd.read_csv(test_csv)

test_dataset = TestDataset(test_meta, test_img_folder, transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)

print("\nExtracting test embeddings on GPU...")
test_embeddings = {}
extraction_start_time = time.time()

with torch.no_grad():
    processed = 0
    for imgs, sample_ids in test_loader:
        imgs = imgs.to(device)  # Move to GPU
        feats = cnn(imgs).cpu().numpy()  # Process on GPU, move to CPU
        for i, sid in enumerate(sample_ids):
            test_embeddings[sid] = feats[i]

        processed += len(imgs)
        if processed % 500 == 0 or processed == len(test_dataset):
            progress_pct = (processed / len(test_dataset)) * 100
            elapsed = time.time() - extraction_start_time
            imgs_per_sec = processed / elapsed if elapsed > 0 else 0
            eta_seconds = (len(test_dataset) - processed) / imgs_per_sec if imgs_per_sec > 0 else 0
            print(f"  Processed {processed}/{len(test_dataset)} images ({progress_pct:.1f}%) | "
                  f"Speed: {imgs_per_sec:.1f} img/s | ETA: {eta_seconds:.1f}s")

extraction_time = time.time() - extraction_start_time
print(f"Embedding extraction complete in {extraction_time:.1f}s")

os.makedirs(r"D:\inna_project\embeddings", exist_ok=True)
torch.save(test_embeddings, r"D:\inna_project\embeddings\test_embeddings.pt")

df_emb = pd.DataFrame.from_dict(test_embeddings, orient="index")
df_emb.reset_index(inplace=True)
df_emb.rename(columns={"index": "sample_id"}, inplace=True)
df_emb.to_csv(r"D:\inna_project\embeddings\test_embeddings.csv", index=False)

print(f"\n{'='*60}")
print(f"SUCCESS! Saved fine-tuned test embeddings")
print(f"PT file: D:\\inna_project\\embeddings\\test_embeddings.pt")
print(f"CSV file: D:\\inna_project\\embeddings\\test_embeddings.csv")
print(f"Shape: {df_emb.shape} (sample_id + {df_emb.shape[1]-1} features)")
print(f"{'='*60}")









"""## using CLIP embeddings"""

import torch, numpy as np, pandas as pd, joblib, os
from scipy import sparse as sp

# --- Load existing combined features and metadata ---
save_path = "/content/drive/MyDrive/model_saves/"
X_combined = joblib.load(f"{save_path}X_combined.joblib")
print("Loaded X_combined:", X_combined.shape)

train_meta = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")[["sample_id"]]
train_meta["sample_id"] = train_meta["sample_id"].astype(str)

# Restrict to aligned rows (same number as X_combined)
train_meta = train_meta.iloc[:X_combined.shape[0]].reset_index(drop=True)
print("Trimmed train_meta to match X_combined:", train_meta.shape)

# --- Load CLIP embeddings ---
torch.serialization.add_safe_globals([np.ndarray, np.core.multiarray._reconstruct])
clip_path = "/content/drive/MyDrive/student_resource/embeddings/clip_embeddings.pt"
clip_dict = torch.load(clip_path, map_location="cpu", weights_only=False)
print("Loaded CLIP embeddings:", len(clip_dict))

# --- Convert CLIP embeddings into DataFrame ---
rows = []
for fname, vec in clip_dict.items():
    sample_id = os.path.splitext(fname)[0]  # assumes filename = sample_id + '.jpg'
    rows.append([sample_id] + list(vec))
clip_df = pd.DataFrame(rows, columns=["sample_id"] + [f"clip_{i}" for i in range(len(vec))])
print("CLIP dataframe:", clip_df.shape)

# --- Align CLIP embeddings with training samples ---
aligned_clip = pd.merge(train_meta, clip_df, on="sample_id", how="left")
aligned_clip = aligned_clip.fillna(0.0)
clip_matrix = aligned_clip.drop(columns=["sample_id"]).to_numpy(dtype=np.float32)
print("Aligned CLIP matrix shape:", clip_matrix.shape)

# --- Replace fine-tuned embeddings with CLIP ---
n_img_features_old = 2048  # adjust to match your fine-tuned embedding size
n_total = X_combined.shape[1]
n_non_img = n_total - n_img_features_old

if sp.issparse(X_combined):
    X_non_img = X_combined[:, :n_non_img]
    X_clip = sp.csr_matrix(clip_matrix)
    X_new = sp.hstack([X_non_img, X_clip], format="csr")
else:
    X_new = np.hstack([X_combined[:, :n_non_img], clip_matrix])

print("New combined shape:", X_new.shape)

# --- Save updated combined matrix ---
joblib.dump(X_new, f"{save_path}X_combined_with_clip.joblib")
print("Saved X_combined_with_clip.joblib successfully.")











import os, joblib, numpy as np, pandas as pd
from scipy import sparse as sp
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import normalize

save_path = "/content/drive/MyDrive/model_saves/"
X_combined = joblib.load(os.path.join(save_path, "X_combined.joblib"))
y = joblib.load(os.path.join(save_path, "y.joblib"))

# load embedding maps (keys = filenames like "123.jpg")
import torch, numpy
torch.serialization.add_safe_globals([numpy.ndarray, numpy.core.multiarray._reconstruct])

clip_dict = torch.load("/content/drive/MyDrive/student_resource/embeddings/clip_embeddings.pt",
                      map_location="cpu", weights_only=False)
resnet_dict = torch.load("/content/drive/MyDrive/student_resource/embeddings/fine_tuned_embeddings.pt",
                         map_location="cpu", weights_only=False)

# Build dataframe of training sample_ids in the same order as X_combined rows
train_meta = pd.read_csv("/content/drive/MyDrive/student_resource/dataset/train.csv")[["sample_id"]]
train_meta["sample_id"] = train_meta["sample_id"].astype(str)
train_meta = train_meta.iloc[: X_combined.shape[0] ].reset_index(drop=True)   # ensure same length

# helper to extract vector by filename -> sample_id mapping
def fname_to_id(fname):
    return os.path.splitext(fname)[0]

# Build aligned matrices (rows in train_meta order)
def build_aligned_matrix(emb_dict, dim):
    rows = []
    for sid in train_meta["sample_id"].astype(str):
        fname = sid + ".jpg"
        vec = emb_dict.get(fname)
        if vec is None:
            rows.append(np.zeros(dim, dtype=np.float32))
        else:
            rows.append(np.array(vec, dtype=np.float32))
    return np.vstack(rows)

# Create matrices
clip_dim = len(next(iter(clip_dict.values())))
resnet_dim = len(next(iter(resnet_dict.values())))
X_clip = build_aligned_matrix(clip_dict, clip_dim)        # (n, 512)
X_resnet = build_aligned_matrix(resnet_dict, resnet_dim)  # (n, 2048)

# Optional: reduce ResNet to 512 dims (keeps memory manageable)
svd_target = 512
if X_resnet.shape[1] > svd_target:
    svd = TruncatedSVD(n_components=svd_target, n_iter=7, random_state=42)
    X_resnet_reduced = svd.fit_transform(X_resnet.astype(np.float32))
else:
    X_resnet_reduced = X_resnet

# Normalize each embedding type independently (L2)
X_clip_n = normalize(X_clip, norm="l2", axis=1)
X_resnet_n = normalize(X_resnet_reduced, norm="l2", axis=1)

# Optional: weight one over the other (tune later); default 1.0
w_clip = 1.0
w_resnet = 1.0

X_img_concat = np.hstack([X_clip_n * w_clip, X_resnet_n * w_resnet]).astype(np.float32)
print("Image concat shape:", X_img_concat.shape)

# Replace old image block in X_combined
# Determine old image width (assumed 2048). If different, set n_img_old accordingly.
n_img_old = 2048
n_total = X_combined.shape[1]
n_non_img = n_total - n_img_old

if sp.issparse(X_combined):
    X_non_img = X_combined[:, :n_non_img]
    X_img_block = sp.csr_matrix(X_img_concat)
    X_new = sp.hstack([X_non_img, X_img_block], format="csr")
else:
    X_new = np.hstack([X_combined[:, :n_non_img], X_img_concat])

# Save combined matrix
joblib.dump(X_new, os.path.join(save_path, "X_combined_with_clip_resnet.joblib"))
print("Saved X_combined_with_clip_resnet.joblib", X_new.shape)

"""## optional visualisations and analysis"""

# X_combined = merged.drop(columns=["sample_id", "price"], errors="ignore").astype(np.float32)
# y = merged["price"].astype(float).values

# y = np.clip(train_df["price"], train_df["price"].quantile(0.01), train_df["price"].quantile(0.99))

# print(X_combined.shape)
# print("NaNs:", np.isnan(X_combined.values).sum())

# X_combined.describe().iloc[:, :5].T  # show first 5 cols only for readability

# text_var = np.var(X_combined.iloc[:, :-256].sample(1000, axis=1))  # sample subset of text cols
# img_var = np.var(X_combined.iloc[:, -256:])
# print("Text variance:", text_var, "| Image variance:", img_var)

# text_var = np.var(X_combined.iloc[:, :-256].sample(1000, axis=1))  # sample subset of text cols
# img_var = np.var(X_combined.iloc[:, -256:])
# print("Text variance:", text_var, "| Image variance:", img_var)

# import matplotlib.pyplot as plt
# plt.hist(y, bins=50)
# plt.title("Target price distribution")
# plt.show()

# print("Duplicate sample_ids:", merged['sample_id'].duplicated().sum())



# import matplotlib.pyplot as plt
# X_combined.var(axis=0).plot(kind="hist", bins=100, figsize=(8,4))
# plt.title("Feature Variance Distribution")
# plt.xlabel("Variance")
# plt.ylabel("Count")
# plt.show()

# import seaborn as sns
# corr = np.corrcoef(
#     X_combined.iloc[:, :1000].mean(axis=1),  # representative text mean
#     X_combined.iloc[:, -256:].mean(axis=1)   # representative image mean
# )
# sns.heatmap(corr, annot=True, fmt=".2f")

# from sklearn.decomposition import PCA
# pca = PCA(n_components=2)
# proj = pca.fit_transform(X_combined.sample(3000))
# plt.scatter(proj[:,0], proj[:,1], c=np.log1p(y[:3000]), cmap="viridis", s=8)
# plt.colorbar(label="log(price)")
# plt.title("PCA Projection Colored by Price")
# plt.show()

# train_merged.info()

# import pandas as pd
# import numpy as np

# import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt

# # subsample to avoid memory crash
# sample = train_merged.sample(n=1000, random_state=42)
# corr = sample.corr(numeric_only=True)

# plt.figure(figsize=(12, 8))
# sns.heatmap(corr.iloc[:50, :50], cmap='coolwarm', center=0)
# plt.title("Correlation heatmap (first 50 features)")
# plt.show()

# from lightgbm import LGBMRegressor

# X_sample = train_merged.drop(columns=["sample_id", "price"])
# y_sample = train_merged["price"]
# model_probe = LGBMRegressor(
#     n_estimators=200, learning_rate=0.05, num_leaves=64, random_state=42
# )
# model_probe.fit(X_sample, y_sample)

# importances = pd.Series(model_probe.feature_importances_, index=X_sample.columns)
# top_feats = importances.nlargest(20)

# top_feats.plot(kind='barh', figsize=(8, 6))
# plt.title("Top 20 Feature Importances (Probe LGBM)")
# plt.gca().invert_yaxis()
# plt.show()

# y_pred_probe = model_probe.predict(X_sample)
# plt.figure(figsize=(8, 5))
# sns.kdeplot(y_sample, label="Actual", fill=True)
# sns.kdeplot(y_pred_probe, label="Predicted", fill=True)
# plt.legend(); plt.title("Distribution Alignment: Actual vs Predicted"); plt.show()

# from joblib import load
# pca = load("/content/drive/MyDrive/student_resource/embeddings/image_pca_256.joblib")
# plt.plot(np.cumsum(pca.explained_variance_ratio_) * 100)
# plt.xlabel("Components")
# plt.ylabel("Cumulative Variance (%)")
# plt.title("PCA Variance Retention Curve")
# plt.grid(True)
# plt.show()

# from scipy.sparse import issparse
# import numpy as np

# if issparse(X_combined):
#     density = X_combined.nnz / (X_combined.shape[0] * X_combined.shape[1])
#     print("Matrix density:", round(density, 6))
# else:
#     density = np.count_nonzero(X_combined) / X_combined.size
#     print("Matrix density:", round(density, 6))

# import pandas as pd
# import numpy as np
# from scipy.sparse import csr_matrix

# # Convert to CSR for efficient slicing
# X_csr = csr_matrix(X_combined)

# # Extract last 256 columns (image PCA)
# dense_part = X_csr[:, -256:].toarray()
# print(pd.DataFrame(dense_part).describe().T)



# import matplotlib.pyplot as plt
# plt.hist(y, bins=50)
# plt.title("Target Distribution")
# plt.show()

# import numpy as np
# from scipy.sparse import csr_matrix

# # Convert to CSR for slicing
# X_csr = csr_matrix(X_combined)

# # Text variance (subset for speed)
# text_sample = X_csr[:, :25384].toarray()[:, :1000]  # only first 1000 TF-IDF cols
# text_var = np.var(text_sample)

# # Image variance
# img_part = X_csr[:, 25384:].toarray()
# img_var = np.var(img_part)

# print("Text var sample:", text_var, " | Image var:", img_var)

# print("Feature dimensionality:", X_combined.shape[1])
# print("Samples per feature ratio:", X_combined.shape[0] / X_combined.shape[1])

# from sklearn.preprocessing import StandardScaler
# X_combined.loc[:, X_combined.columns.str.startswith("img_")] /= 2

# scaler = StandardScaler()
# X_scaled = scaler.fit_transform(X_combined)

# y_log = np.log1p(y)



"""# log transform"""

import numpy as np

y_log = np.log1p(y)
print(y_log.shape, y_log.min(), y_log.max())

"""# Model train"""

save_path = "/content/drive/MyDrive/model_saves/"

# pip install catboost -q

from google.colab import drive
import joblib

# Mount Drive
drive.mount('/content/drive')

# Load saved data
save_path = "/content/drive/MyDrive/model_saves/"

X_full = joblib.load(f"{save_path}X_combined.joblib")   # your combined features
y = joblib.load(f"{save_path}y.joblib")         # or y.joblib if unclipped

print("X_full shape:", X_full.shape)
print("y shape:", y.shape)

X_full, y_log

# # ============================================================
# # STACKED MODEL (CRASH-PROOF + MEMORY-SAFE)
# # ============================================================
# import numpy as np, pandas as pd, joblib, gc, os
# from sklearn.model_selection import KFold
# from sklearn.linear_model import Ridge, ElasticNet
# from sklearn.preprocessing import MaxAbsScaler
# from lightgbm import LGBMRegressor, early_stopping, log_evaluation
# from catboost import CatBoostRegressor
# from scipy import sparse as sp
# from google.colab import drive

# # --- SMAPE ---
# def smape_price(y_true_log, y_pred_log):
#     y_true, y_pred = np.expm1(y_true_log), np.expm1(y_pred_log)
#     denom = (np.abs(y_true) + np.abs(y_pred)) / 2
#     diff = np.abs(y_true - y_pred) / np.clip(denom, 1e-8, None)
#     return np.mean(diff) * 100

# # ============================================================
# # STEP 0 â€” LOAD + PREP
# # ============================================================
# drive.mount('/content/drive', force_remount=True)
# save_path = "/content/drive/MyDrive/model_saves/"

# X_full = joblib.load(f"{save_path}X_combined.joblib")
# y = joblib.load(f"{save_path}y.joblib")

# if not sp.issparse(X_full):
#     X_full = sp.csr_matrix(X_full)

# y_log_aligned = np.log1p(y).astype(np.float32)
# n_text_features = 25384

# gc.collect()

# # ============================================================
# # STEP 1 â€” TEXT WEIGHTING
# # ============================================================
# text_weight = 1.8
# print(f"Applying text weight: {text_weight}")

# X_text_aligned = X_full[:, :n_text_features].multiply(text_weight)
# X_img_hc_aligned = X_full[:, n_text_features:]
# X_scaled = sp.hstack([X_text_aligned, X_img_hc_aligned], format="csr")
# del X_full
# gc.collect()

# # ============================================================
# # STEP 2 â€” LIGHT INTERACTIONS (SPARSE SAFE)
# # ============================================================
# print("Generating lightweight interactions...")
# img_mean = np.array(X_scaled[:, -256:].mean(axis=1)).ravel()
# text_mean = np.array(X_scaled[:, :1500].mean(axis=1)).ravel()

# interaction_1 = img_mean * text_mean
# interaction_2 = np.abs(img_mean - text_mean)

# X_aug = sp.hstack([
#     X_scaled,
#     sp.csr_matrix(np.vstack([interaction_1, interaction_2]).T, dtype=np.float32)
# ], format="csr")

# del X_scaled, img_mean, text_mean, interaction_1, interaction_2
# gc.collect()

# # ============================================================
# # STEP 3 â€” SCALE (SPARSE-SAFE)
# # ============================================================
# print("Scaling features with MaxAbsScaler...")
# scaler = MaxAbsScaler(copy=False)
# X_aug_scaled = scaler.fit_transform(X_aug)
# del X_aug
# gc.collect()

# # ============================================================
# # STEP 4 â€” MODEL CONFIGS (REDUCED SIZE)
# # ============================================================
# params_lgb1 = dict(
#     n_estimators=900, learning_rate=0.035, max_depth=8, num_leaves=96,
#     subsample=0.8, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=0.8,
#     random_state=42, n_jobs=-1, device='gpu', force_col_wise=True
# )

# params_lgb2 = dict(
#     n_estimators=700, learning_rate=0.04, max_depth=7, num_leaves=72,
#     subsample=0.8, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=0.7,
#     random_state=99, n_jobs=-1, device='gpu', force_col_wise=True
# )

# # CatBoost â†’ CPU (GPU OOMs)
# params_cat = dict(
#     iterations=500, learning_rate=0.05, depth=7, l2_leaf_reg=6,
#     loss_function="MAE", verbose=False, random_seed=42
# )

# # ============================================================
# # STEP 5 â€” TRAIN (2 FOLDS)
# # ============================================================
# kf = KFold(n_splits=2, shuffle=True, random_state=42)
# n = X_aug_scaled.shape[0]

# oof_lgb1 = np.zeros(n, dtype=np.float32)
# oof_lgb2 = np.zeros(n, dtype=np.float32)
# oof_cat  = np.zeros(n, dtype=np.float32)
# oof_ridge = np.zeros(n, dtype=np.float32)
# oof_enet  = np.zeros(n, dtype=np.float32)
# fold_models = {"lgb1": [], "lgb2": [], "cat": [], "ridge": [], "enet": []}

# for fold, (tr, va) in enumerate(kf.split(X_aug_scaled), 1):
#     print(f"\n--- Fold {fold}/2 ---")
#     X_tr, X_va = X_aug_scaled[tr], X_aug_scaled[va]
#     y_tr, y_va = y_log_aligned[tr], y_log_aligned[va]

#     m1 = LGBMRegressor(**params_lgb1)
#     m1.fit(X_tr, y_tr, eval_set=[(X_va, y_va)],
#            callbacks=[early_stopping(60), log_evaluation(200)])
#     oof_lgb1[va] = m1.predict(X_va)
#     fold_models["lgb1"].append(m1)
#     del m1; gc.collect()

#     m2 = LGBMRegressor(**params_lgb2)
#     m2.fit(X_tr, y_tr, eval_set=[(X_va, y_va)],
#            callbacks=[early_stopping(60), log_evaluation(200)])
#     oof_lgb2[va] = m2.predict(X_va)
#     fold_models["lgb2"].append(m2)
#     del m2; gc.collect()

#     mc = CatBoostRegressor(**params_cat)
#     mc.fit(X_tr, y_tr)
#     oof_cat[va] = mc.predict(X_va)
#     fold_models["cat"].append(mc)
#     del mc; gc.collect()

#     mr = Ridge(alpha=1.0)
#     mr.fit(X_tr, y_tr)
#     oof_ridge[va] = mr.predict(X_va)
#     del mr; gc.collect()

#     me = ElasticNet(alpha=0.001, l1_ratio=0.5, random_state=42)
#     me.fit(X_tr, y_tr)
#     oof_enet[va] = me.predict(X_va)
#     del me; gc.collect()

#     print(f"Fold {fold} SMAPE:", smape_price(y_va, oof_lgb1[va]))

#     del X_tr, X_va, y_tr, y_va
#     gc.collect()

# # ============================================================
# # STEP 6 â€” META STACK
# # ============================================================
# X_meta = np.vstack([oof_lgb1, oof_lgb2, oof_cat, oof_ridge, oof_enet]).T
# meta = Ridge(alpha=0.5)
# meta.fit(X_meta, y_log_aligned)
# meta_oof = meta.predict(X_meta)

# # ============================================================
# # STEP 7 â€” REPORT + SAVE
# # ============================================================
# print("\n--- Validation SMAPE ---")
# print(f"LGB1  : {smape_price(y_log_aligned, oof_lgb1):.2f}%")
# print(f"LGB2  : {smape_price(y_log_aligned, oof_lgb2):.2f}%")
# print(f"CAT   : {smape_price(y_log_aligned, oof_cat):.2f}%")
# print(f"RIDGE : {smape_price(y_log_aligned, oof_ridge):.2f}%")
# print(f"ENET  : {smape_price(y_log_aligned, oof_enet):.2f}%")
# print(f"STACK : {smape_price(y_log_aligned, meta_oof):.2f}%")

# joblib.dump(fold_models, f"{save_path}fold_models_final_stable.joblib")
# joblib.dump(meta, f"{save_path}meta_ridge_final_stable.joblib")
# joblib.dump(scaler, f"{save_path}feature_scaler_final_stable.joblib")
# print("\nAll models saved successfully.")

import numpy as np
from sklearn.model_selection import train_test_split
from lightgbm import LGBMRegressor, early_stopping, log_evaluation

# --- Log-transform target ---
y_log = np.log1p(y)

# --- Split ---
X_train, X_val, y_train, y_val = train_test_split(
    X_full, y_log, train_size=0.7, random_state=42
)

# --- Train ---
model = LGBMRegressor(
    n_estimators=6000,
    learning_rate=0.012,
    max_depth=10,
    num_leaves=160,
    subsample=0.7,
    colsample_bytree=0.5,
    reg_alpha=0.6,
    reg_lambda=1.0,
    min_data_in_leaf=40,
    min_gain_to_split=0.05,
    random_state=42,
    n_jobs=-1
)

model.fit(
    X_train, y_train,
    eval_set=[(X_val, y_val)],
    eval_metric="l1",
    callbacks=[early_stopping(stopping_rounds=300), log_evaluation(period=100)]
)

# --- Evaluate ---
def smape(y_true, y_pred):
    denom = (np.abs(y_true) + np.abs(y_pred)) / 2
    diff = np.abs(y_true - y_pred) / np.clip(denom, 1e-8, None)
    return np.mean(diff) * 100

y_pred_val = np.expm1(model.predict(X_val))
y_true_val = np.expm1(y_val)
val_smape = smape(y_true_val, y_pred_val)
print(f"Validation SMAPE: {val_smape:.2f}%")

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from lightgbm import LGBMRegressor, early_stopping, log_evaluation
from scipy import sparse
import joblib

# ============================================================
# LOAD FEATURE MATRIX + TARGET
# ============================================================
X_full = joblib.load("/content/drive/MyDrive/model_saves/X_combined.joblib")
y = joblib.load("/content/drive/MyDrive/model_saves/y.joblib")

y_log = np.log1p(y)

# Handle sparse/dense
if sparse.issparse(X_full):
    n_samples = X_full.shape[0]
    X_arr = X_full
else:
    X_arr = X_full.values if isinstance(X_full, pd.DataFrame) else X_full
    n_samples = X_arr.shape[0]

y_arr = y_log.values if isinstance(y_log, (pd.Series, pd.DataFrame)) else y_log
y_arr = np.asarray(y_arr).reshape(-1)
assert n_samples == len(y_arr), "Mismatch between X and y lengths"

# ============================================================
# PARAMETER GRID (bounded for ~2h runtime)
# ============================================================
param_grid = [
    dict(device_type='gpu', n_estimators=2500, learning_rate=0.020, max_depth=10, num_leaves=160,
         subsample=0.7, colsample_bytree=0.5, reg_alpha=0.6, reg_lambda=1.0,
         min_data_in_leaf=40, min_gain_to_split=0.05, random_state=42, n_jobs=-1),

    dict(device_type='gpu', n_estimators=2500, learning_rate=0.018, max_depth=12, num_leaves=200,
         subsample=0.8, colsample_bytree=0.6, reg_alpha=0.4, reg_lambda=1.2,
         min_data_in_leaf=50, min_gain_to_split=0.1, random_state=52, n_jobs=-1),

    dict(device_type='gpu', n_estimators=2500, learning_rate=0.022, max_depth=8, num_leaves=128,
         subsample=0.65, colsample_bytree=0.7, reg_alpha=0.8, reg_lambda=0.8,
         min_data_in_leaf=30, min_gain_to_split=0.03, random_state=64, n_jobs=-1)
]

# ============================================================
# 3-FOLD CROSS-VALIDATION (runtime cap)
# ============================================================
kf = KFold(n_splits=3, shuffle=True, random_state=42)
models = []
oof_preds = np.zeros(n_samples)
oof_true = np.zeros(n_samples)

# ============================================================
# TRAINING LOOP
# ============================================================
for fold, (train_idx, val_idx) in enumerate(kf.split(X_arr), 1):
    print(f"\n{'='*20} Fold {fold} {'='*20}")
    X_train, X_val = X_arr[train_idx], X_arr[val_idx]
    y_train, y_val = y_arr[train_idx], y_arr[val_idx]

    fold_models = []
    for i, params in enumerate(param_grid, 1):
        print(f"  Training model {i}/{len(param_grid)} in fold {fold}")
        model = LGBMRegressor(**params)
        model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            eval_metric="l1",
            callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=200)]
        )
        fold_models.append(model)

    models.append(fold_models)
    preds_val_log = np.mean(
        [m.predict(X_val, num_iteration=m.best_iteration_) for m in fold_models],
        axis=0
    )
    oof_preds[val_idx] = preds_val_log
    oof_true[val_idx] = y_val

# ============================================================
# SMAPE METRIC
# ============================================================
def smape(y_true, y_pred):
    denom = (np.abs(y_true) + np.abs(y_pred)) / 2
    diff = np.abs(y_true - y_pred) / np.clip(denom, 1e-8, None)
    return np.mean(diff) * 100

y_pred_oof = np.expm1(oof_preds)
y_true_oof = np.expm1(oof_true)
oof_smape = smape(y_true_oof, y_pred_oof)

print(f"\n{'='*60}\nOOF SMAPE (3-fold Ã— 3-model ensemble): {oof_smape:.2f}%\n{'='*60}")

import joblib, os

save_dir = "/content/drive/MyDrive/model_saves/lgbm_folds"
os.makedirs(save_dir, exist_ok=True)

for fold_idx, fold_models in enumerate(models, 1):
    for i, model in enumerate(fold_models, 1):
        path = f"{save_dir}/lgbm_fold{fold_idx}_model{i}.joblib"
        joblib.dump(model, path)
        print("Saved:", path)

print("âœ… All trained fold models saved.")

import joblib
import os

# Ensure directory exists in Drive
os.makedirs("/content/drive/MyDrive/student_resource/models", exist_ok=True)

# Save current trained model
joblib.dump(model, "/content/drive/MyDrive/student_resource/models/lgbm_price_regressor_43_66.pkl")
print("Saved LightGBM model â†’ /content/drive/MyDrive/student_resource/models/lgbm_price_regressor_43_66.pkl")

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""## improvement visuals"""

# --- Analysis block (run standalone) ---
import joblib
import numpy as np
import pandas as pd
from scipy.sparse import issparse
from lightgbm import LGBMRegressor
from scipy.stats import skew

save_path = "/content/drive/MyDrive/model_saves/"

# --- Load ---
X_full = joblib.load(f"{save_path}X_combined.joblib")
y = joblib.load(f"{save_path}y.joblib")

# --- Verify CSR and basic info ---
print("Type:", type(X_full))
if issparse(X_full):
    print("CSR matrix detected, shape:", X_full.shape)

# --- Feature importance using LightGBM ---

import joblib
model = joblib.load(f"{save_path}lgbm_single_model.joblib")
importances = model.feature_importances_


# --- Summarize ---
feat_idx = np.arange(X_full.shape[1])
imp_df = pd.DataFrame({"feature_index": feat_idx, "importance": importances})
imp_df = imp_df.sort_values("importance", ascending=False)
print("\nTop 20 features by importance:")
print(imp_df.head(20))

# --- Optional: small dense subset for rough skewness stats ---
sample_dense = X_full[:5000].toarray()  # only small slice
sample_df = pd.DataFrame(sample_dense[:, :min(100, X_full.shape[1])])
skew_vals = np.apply_along_axis(skew, 0, sample_df)
print("\nApproximate skewness stats (first 100 cols):")
print(pd.Series(skew_vals).describe())







"""## clip model"""

# # ============================================================
# # TRAIN LIGHTGBM MODEL ON CLIP-MERGED FEATURES
# # ============================================================
# import numpy as np
# import joblib, os
# from sklearn.model_selection import train_test_split
# from lightgbm import LGBMRegressor, early_stopping, log_evaluation
# from google.colab import drive

# # --- Mount and define paths ---
# drive.mount('/content/drive', force_remount=True)
# save_path = "/content/drive/MyDrive/model_saves/"

# # --- Load data ---
# X_full = joblib.load(f"{save_path}X_combined.joblib")
# y = joblib.load(f"{save_path}y.joblib")

# print("Loaded X_full:", X_full.shape)
# print("Loaded y:", y.shape)

# # --- Log-transform target ---
# y_log = np.log1p(y)

# # --- Split ---
# X_train, X_val, y_train, y_val = train_test_split(
#     X_full, y_log, train_size=0.7, random_state=42
# )

# # --- Train model ---
# model = LGBMRegressor(
#     objective='huber',
#     alpha=0.85,
#     n_estimators=6000,
#     learning_rate=0.01,
#     max_depth=8,
#     num_leaves=80,
#     subsample=0.8,
#     colsample_bytree=0.7,
#     bagging_freq=1,
#     feature_fraction_bynode=0.8,
#     reg_alpha=1.2,
#     reg_lambda=2.0,
#     min_child_samples=80,
#     min_split_gain=0.1,
#     random_state=42,
#     n_jobs=-1
# )


# model.fit(
#     X_train, y_train,
#     eval_set=[(X_val, y_val)],
#     eval_metric="l1",
#     callbacks=[early_stopping(stopping_rounds=300), log_evaluation(period=100)]
# )

# # --- Evaluate ---
# def smape(y_true, y_pred):
#     denom = (np.abs(y_true) + np.abs(y_pred)) / 2
#     diff = np.abs(y_true - y_pred) / np.clip(denom, 1e-8, None)
#     return np.mean(diff) * 100

# y_pred_val = np.expm1(model.predict(X_val))
# y_true_val = np.expm1(y_val)
# val_smape = smape(y_true_val, y_pred_val)
# print(f"\nValidation SMAPE: {val_smape:.2f}%")

# # --- Save trained model ---
# os.makedirs(save_path, exist_ok=True)
# joblib.dump(model, f"{save_path}lgbm_2_model.joblib")
# print(f"\nModel saved successfully to {save_path}lgbm_2_model.joblib")



"""## VALIDATION TRAINING"""

# ============================================================
# VALIDATION PREDICTION NOTEBOOK (SEPARATE)
# ============================================================
import numpy as np
import pandas as pd
import joblib
from lightgbm import LGBMRegressor
from google.colab import drive

# --- Mount Drive and set paths ---
drive.mount('/content/drive', force_remount=True)
save_path = "/content/drive/MyDrive/model_saves/"

# --- Load artifacts ---
model = joblib.load(f"{save_path}lgbm_single_model.joblib")

# You must have saved X_train, X_val, y_train, y_val earlier
X_train = joblib.load(f"{save_path}X_train.joblib")
X_val = joblib.load(f"{save_path}X_val.joblib")
y_train = joblib.load(f"{save_path}y_train.joblib")
y_val = joblib.load(f"{save_path}y_val.joblib")

# --- Predict on validation set ---
print("Predicting on validation data...")
y_pred_val_log = model.predict(X_val)
y_pred_val = np.expm1(y_pred_val_log)
y_true_val = np.expm1(y_val)

# --- SMAPE evaluation ---
def smape(y_true, y_pred):
    denom = (np.abs(y_true) + np.abs(y_pred)) / 2
    diff = np.abs(y_true - y_pred) / np.clip(denom, 1e-8, None)
    return np.mean(diff) * 100

val_smape = smape(y_true_val, y_pred_val)
print(f"Validation SMAPE: {val_smape:.2f}%")

# --- Save predictions for inspection ---
val_preds_df = pd.DataFrame({
    "y_true": y_true_val,
    "y_pred": y_pred_val
})
val_preds_df.to_csv(f"{save_path}val_predictions.csv", index=False)
print(f"Validation predictions saved to {save_path}val_predictions.csv")

"""## test merge and predict"""

# ============================================================
# BUILD TEST FEATURE MATRIX: TF-IDF + STATS + FINE-TUNED IMAGE EMBEDDINGS
# ============================================================

import os, numpy as np, pandas as pd, scipy.sparse as sp, torch, joblib
from google.colab import drive

# ------------------------------------------------------------
# 1. MOUNT DRIVE + PATHS
# ------------------------------------------------------------
drive.mount("/content/drive", force_remount=True)
base_path = "/content/drive/MyDrive/student_resource"
save_path = "/content/drive/MyDrive/model_saves"
os.makedirs(save_path, exist_ok=True)

# ------------------------------------------------------------
# 2. LOAD PRE-SAVED TEXT FEATURES
# ------------------------------------------------------------
X_text_test = sp.load_npz(f"{base_path}/text_tfidf_test.npz")
text_ids_test = pd.read_csv(f"{base_path}/text_tfidf_test_ids.csv")
test_df = pd.read_csv(f"{base_path}/dataset/test_clean.csv")

# ------------------------------------------------------------
# 3. LOAD FINE-TUNED IMAGE EMBEDDINGS
# ------------------------------------------------------------
torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])
fine_tuned_test = torch.load(
    f"{base_path}/embeddings/fine_tuned_embeddings_test.pt",
    map_location="cpu",
    weights_only=False
)

# ------------------------------------------------------------
# 4. CONVERT EMBEDDINGS â†’ DATAFRAME
# ------------------------------------------------------------
rows = []
for fname, vec in fine_tuned_test.items():
    sid = os.path.splitext(fname)[0]
    rows.append([sid] + list(vec))
img_features_test = pd.DataFrame(rows, columns=["sample_id"] + [f"img_{i}" for i in range(len(vec))])

# ------------------------------------------------------------
# 5. ALIGN IDs + MERGE AUXILIARY TEXT FEATURES
# ------------------------------------------------------------
aux_cols = ["text_len", "word_count", "digit_ratio", "avg_word_len", "text_cluster"]
aux_features_test = test_df[["sample_id"] + aux_cols]

text_ids_test["sample_id"] = text_ids_test["sample_id"].astype(str)
img_features_test["sample_id"] = img_features_test["sample_id"].astype(str)
aux_features_test["sample_id"] = aux_features_test["sample_id"].astype(str)

merged_test = (
    text_ids_test
    .merge(img_features_test, on="sample_id", how="inner")
    .merge(aux_features_test, on="sample_id", how="left")
)

print(f"Merged test rows: {merged_test.shape[0]}")

# ------------------------------------------------------------
# 6. BUILD FINAL SPARSE TEST FEATURE MATRIX
# ------------------------------------------------------------
X_text_test = X_text_test.tocsr()
idx_text = range(X_text_test.shape[0])

# Drop identifiers, convert numerical features to array
X_num = merged_test.iloc[idx_text].drop(columns=["sample_id"], errors="ignore").to_numpy(dtype=np.float32)

# Concatenate TF-IDF + numerical features
X_full_test = sp.hstack([X_text_test, sp.csr_matrix(X_num)], format="csr")

print("Final test feature shape:", X_full_test.shape)

# ------------------------------------------------------------
# 7. SAVE FINAL TEST FEATURES
# ------------------------------------------------------------
joblib.dump(X_full_test, f"{save_path}/X_combined_test.joblib")
print(f"âœ… Saved combined test embeddings â†’ {save_path}/X_combined_test.joblib")

# ============================================================
# TEST PREDICTION USING SAVED ENSEMBLE MODELS
# ============================================================

import os, joblib, numpy as np, pandas as pd
from glob import glob

# ------------------------------------------------------------
# 1. LOAD TEST FEATURES + MODEL ENSEMBLE
# ------------------------------------------------------------
save_path = "/content/drive/MyDrive/model_saves"
base_path = "/content/drive/MyDrive/student_resource"
fold_dir  = f"{save_path}/lgbm_folds"

X_test = joblib.load(f"{save_path}/X_combined_test.joblib")
text_ids_test = pd.read_csv(f"{base_path}/text_tfidf_test_ids.csv")

# Find all saved models
model_paths = sorted(glob(f"{fold_dir}/lgbm_fold*_model*.joblib"))
print(f"Found {len(model_paths)} models â†’ averaging predictions")

# ------------------------------------------------------------
# 2. GENERATE ENSEMBLE PREDICTIONS
# ------------------------------------------------------------
preds_log = np.zeros(X_test.shape[0])

for path in model_paths:
    model = joblib.load(path)
    preds_log += model.predict(X_test, num_iteration=model.best_iteration_)
    print("Loaded:", os.path.basename(path))

# Average predictions across ensemble
preds_log /= len(model_paths)

# Reverse log1p transform + enforce positive prices
y_pred = np.expm1(preds_log)
y_pred = np.clip(y_pred, 0, None)

# ------------------------------------------------------------
# 3. BUILD SUBMISSION FILE
# ------------------------------------------------------------
submission = pd.DataFrame({
    "sample_id": text_ids_test["sample_id"].astype(str),
    "price": y_pred.astype(float)
})

out_path = f"{save_path}/test_out.csv"
submission.to_csv(out_path, index=False)

print(f"\nâœ… Saved submission file â†’ {out_path}")
print(f"Total predictions: {len(submission)}")
print(submission.head())

# import pandas as pd
# import numpy as np
# import joblib

# # --- Load test IDs and model ---
# test_ids = pd.read_csv("/content/drive/MyDrive/student_resource/text_tfidf_test_ids.csv")
# model = joblib.load("/content/drive/MyDrive/model_saves/final_model.joblib")  # adjust if different
# X_test = joblib.load("/content/drive/MyDrive/model_saves/X_combined_test.joblib")

# # --- Predict ---
# y_pred = model.predict(X_test)

# # --- Ensure positive float values ---
# y_pred = np.clip(y_pred, a_min=0, a_max=None).astype(float)

# # --- Build final submission DataFrame ---
# submission = pd.DataFrame({
#     "sample_id": test_ids["sample_id"].astype(str),
#     "price": y_pred
# })

# # --- Save to CSV (no index, exact format) ---
# out_path = "/content/drive/MyDrive/student_resource/test_out.csv"
# submission.to_csv(out_path, index=False, float_format="%.6f")

# print("Saved submission file â†’", out_path)
# print(submission.head())

